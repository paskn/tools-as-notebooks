{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1S0esgJ0aoGSqgSvtuz17NA6nb4Ca3TJC",
      "authorship_tag": "ABX9TyND4FLP4uZUE2OU9pkoI4TP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paskn/tools-as-notebooks/blob/main/Add%20Lemmatize_docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss4YUjSRcx5d"
      },
      "source": [
        "# Text Lemmatization Tool\n",
        "\n",
        "**Purpose:** This notebook lemmatizes English language texts stored in a CSV file.\n",
        "\n",
        "**Inputs:**\n",
        "*   A CSV file where one column contains the text to be lemmatized.\n",
        "*   The name of the column containing the text.\n",
        "*   The desired name for the output file.\n",
        "\n",
        "**Outputs:**\n",
        "*   A new CSV file, which is a copy of your input CSV with an added 'text_lemmatized' column. This file will be saved to your Google Drive in a directory named `Colab_Data` and will also be available for direct download.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Run the cells in this notebook sequentially from top to bottom.\n",
        "2.  When prompted, upload your CSV file.\n",
        "3.  Configure the parameters in the 'User Input Configuration' section.\n",
        "4.  Follow the prompts for Google Drive authentication if you haven't used Colab with your Drive recently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "Install Necessary Libraries",
        "cellView": "form",
        "id": "qGi-g1m7cx5d"
      },
      "source": [
        "#@title Step 1: Install libraries required for the notebook.\n",
        "# It will only run once or if the libraries are not already installed in your Colab environment.\n",
        "print(\"Installing pandas and spacy...\")\n",
        "!pip install pandas spacy -q\n",
        "!python -m spacy download en_core_web_sm\n",
        "print(\"Installation complete.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "Import Libraries",
        "cellView": "form",
        "id": "_XIKYMlycx5u"
      },
      "source": [
        "#@title Step 2: Import the libraries needed for the script.\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import os # Will be used for checking Google Drive path\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "print(\"Libraries imported.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "Mount Google Drive & Prepare Output Directory",
        "cellView": "form",
        "id": "OHaPWI2rcx5u"
      },
      "source": [
        "#@title Step 3:  Mount your Google Drive to Colab, allowing the notebook to save files.\n",
        "# It also creates a directory named 'Colab_Data' in your Drive if it doesn't already exist.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "output_directory = '/content/drive/MyDrive/Colab_Data'\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "    print(f\"Directory '{output_directory}' created in your Google Drive.\")\n",
        "else:\n",
        "    print(f\"Directory '{output_directory}' already exists in your Google Drive.\")\n",
        "\n",
        "# Test file to ensure Drive is writable (optional, can be removed)\n",
        "try:\n",
        "    with open(os.path.join(output_directory, 'drive_test.txt'), 'w') as f:\n",
        "        f.write('Google Drive connection successful.')\n",
        "    print(\"Successfully wrote a test file to Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error writing to Google Drive: {e}\")\n",
        "    print(\"Please ensure you have granted necessary permissions and have space in your Drive.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "Upload Your CSV File",
        "cellView": "form",
        "id": "Kuarr7UTcx5u"
      },
      "source": [
        "#@title Step 4: Upload Your CSV File\n",
        "# Run this cell to upload your CSV file containing the text to be lemmatized.\n",
        "# The file should have one column with the text data you want to process.\n",
        "\n",
        "print(\"Please upload your CSV file.\")\n",
        "uploaded_file = files.upload()\n",
        "\n",
        "# Get the name of the uploaded file\n",
        "# Assuming only one file is uploaded\n",
        "if uploaded_file:\n",
        "    input_csv_name = next(iter(uploaded_file))\n",
        "    print(f\"Uploaded file '{input_csv_name}' successfully.\")\n",
        "    # Optional: Display first few lines to confirm it's a CSV\n",
        "    # try:\n",
        "    #   df_preview = pd.read_csv(input_csv_name)\n",
        "    #   print(\"Preview of your uploaded data:\")\n",
        "    #   print(df_preview.head())\n",
        "    # except Exception as e:\n",
        "    #   print(f\"Could not read the uploaded file as CSV: {e}. Please ensure it's a valid CSV.\")\n",
        "else:\n",
        "    input_csv_name = None\n",
        "    print(\"No file uploaded. Please run this cell again to upload your data.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "User Input Configuration",
        "cellView": "form",
        "id": "b7Yr5dgscx5u"
      },
      "source": [
        "#@title Step 5: Configure Parameters\n",
        "# Please specify the details for your lemmatization.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Input Data Configuration\n",
        "#@markdown Enter the name of the column in your CSV that contains the text:\n",
        "text_column_name = \"text\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Output File Configuration\n",
        "#@markdown Enter the desired name for your output CSV file (e.g., `lemmatized_results.csv`):\n",
        "output_filename = \"lemmatized_output.csv\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "print(\"Parameters configured:\")\n",
        "print(f\"  Text column name: '{text_column_name}'\")\n",
        "print(f\"  Output filename: '{output_filename}'\")\n",
        "\n",
        "# Basic validation for output filename\n",
        "if not output_filename.endswith('.csv'):\n",
        "    output_filename += '.csv'\n",
        "    print(f\"  Adjusted output filename to: '{output_filename}' (ensured .csv extension)\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "Perform Lemmatization",
        "cellView": "form",
        "id": "G86Yp2eccx5u"
      },
      "source": [
        "#@title Step 6: Perform Lemmatization\n",
        "# This cell processes your data and performs lemmatization.\n",
        "\n",
        "# Ensure a file was uploaded and parameters are set\n",
        "if input_csv_name is None:\n",
        "    print(\"Error: No CSV file was uploaded. Please go back to the 'Upload Your CSV File' cell and upload your data.\")\n",
        "elif not text_column_name:\n",
        "    print(\"Error: The 'text_column_name' is not specified. Please go to 'Configure Parameters' and set it.\")\n",
        "else:\n",
        "    try:\n",
        "        print(f\"Reading uploaded CSV file: {input_csv_name}...\")\n",
        "        df = pd.read_csv(input_csv_name)\n",
        "        print(\"CSV file loaded successfully.\")\n",
        "\n",
        "        if text_column_name not in df.columns:\n",
        "            print(f\"Error: Column '{text_column_name}' not found in the uploaded CSV.\")\n",
        "            print(f\"Available columns are: {df.columns.tolist()}\")\n",
        "        else:\n",
        "            print(f\"Using column '{text_column_name}' for lemmatization.\")\n",
        "\n",
        "            # Function to lemmatize text\n",
        "            def lemmatize_filter_stopwords_and_nonalpha(text):\n",
        "                # Handle potential NaN or non-string values\n",
        "                if not isinstance(text, str) or not text.strip(): # also check for empty/whitespace-only strings\n",
        "                    return \"\"\n",
        "\n",
        "                doc = nlp(text)\n",
        "                filtered_lemmas = []\n",
        "\n",
        "                for token in doc:\n",
        "                    # 1. Get the lemma and convert to lowercase\n",
        "                    #    Handle pronouns like 'I', 'me', 'he' which spaCy lemmatizes to \"-PRON-\"\n",
        "                    #    We'll use the original text (lowercased) for pronouns.\n",
        "                    if token.lemma_ == \"-PRON-\":\n",
        "                        lemma = token.text.lower()\n",
        "                    else:\n",
        "                        lemma = token.lemma_.lower()\n",
        "\n",
        "                    # 2. Filter:\n",
        "                    #    - Check if the original token is alphabetic (token.is_alpha)\n",
        "                    #    - Check if the (lowercase) lemma is not a stopword\n",
        "                    #    - Optional: Check for minimum length (e.g., len(lemma) > 1)\n",
        "                    if token.is_alpha and lemma not in STOP_WORDS:\n",
        "                        filtered_lemmas.append(lemma)\n",
        "\n",
        "                return \" \".join(filtered_lemmas)\n",
        "\n",
        "            print(\"Applying lemmatization...\")\n",
        "            df['text_lemmatized'] = df[text_column_name].fillna(\"\").astype(str).apply(lemmatize_filter_stopwords_and_nonalpha)\n",
        "            print(\"Lemmatization complete.\")\n",
        "            print(\"Preview of data with lemmatized text:\")\n",
        "            print(df[[text_column_name, 'text_lemmatized']].head())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during lemmatization: {e}\")\n",
        "        df = None # Ensure df is None if there's an error"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "Save and Download Results",
        "cellView": "form",
        "id": "CbW3PCYzcx5u"
      },
      "source": [
        "#@title Step 7: Save Results to Google Drive and Provide Download Link\n",
        "\n",
        "if 'df' in globals() and df is not None and 'text_lemmatized' in df.columns:\n",
        "    try:\n",
        "        # Construct the full path for saving in Google Drive\n",
        "        output_drive_path = os.path.join(output_directory, output_filename)\n",
        "\n",
        "        print(f\"Saving the results to: {output_drive_path} ...\")\n",
        "        df.to_csv(output_drive_path, index=False)\n",
        "        print(\"File saved successfully to your Google Drive.\")\n",
        "\n",
        "        print(f\"Providing download link for '{output_filename}' ...\")\n",
        "        files.download(output_drive_path) # Offer direct download as well\n",
        "        print(f\"If the download doesn't start automatically, please check your browser's download permissions for this site.\")\n",
        "\n",
        "        print(\"\\n--- Results Summary ---\")\n",
        "        print(\"First 10 rows of the output data:\")\n",
        "        print(df.head(10))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving or downloading the file: {e}\")\n",
        "elif 'df' in globals() and df is not None and 'text_lemmatized' not in df.columns:\n",
        "    print(\"Error: The 'text_lemmatized' column was not successfully created. Cannot save results.\")\n",
        "    print(\"Please check the 'Perform Lemmatization' cell for errors.\")\n",
        "else:\n",
        "    print(\"Error: No data to save. Please ensure the previous steps ran correctly and produced a DataFrame 'df'.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL4O8S83cx5u"
      },
      "source": [
        "---\n",
        "# âœ… Lemmatization Complete!\n",
        "\n",
        "Thank you for using the Text Lemmatization Tool!\n",
        "\n",
        "Your results have been:\n",
        "1.  Saved to your Google Drive in the `Colab_Data` folder (as `[Your Output File Name]`).\n",
        "2.  Offered as a direct download to your computer.\n",
        "\n",
        "**Troubleshooting & Tips:**\n",
        "*   **File Not Found Errors:** Ensure you've uploaded your CSV and that the Google Drive path is correct and accessible.\n",
        "*   **Incorrect Text Column:** Double-check the column name specified in the \"Configure Parameters\" section matches exactly with your CSV.\n",
        "*   **CSV Encoding:** This notebook assumes UTF-8 encoding for CSV files. If you encounter reading errors, your file might have a different encoding.\n",
        "*   **Permissions:** If Google Drive saving fails, ensure Colab has the necessary permissions to access your Drive. You might need to re-run the \"Mount Google Drive\" cell.\n",
        "*   **Large Files:** Processing very large files can take time and might hit Colab's resource limits. Consider processing data in chunks if needed.\n",
        "\n",
        "If you encounter other issues, reviewing the error messages in each cell can provide clues."
      ]
    }
  ]
}
