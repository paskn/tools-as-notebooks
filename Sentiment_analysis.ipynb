{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Tool\n",
    "\n",
    "**Purpose:** This notebook performs sentiment analysis on a CSV file containing lemmatized text. It uses a dictionary-based approach to classify each text entry as positive, negative, or neutral.\n",
    "\n",
    "**Inputs:**\n",
    "*   A CSV file where one column contains lemmatized text.\n",
    "*   The name of the column containing the lemmatized text.\n",
    "*   (Optional) A custom sentiment lexicon file (CSV format with 'word' and 'sentiment_score' columns).\n",
    "*   The desired name for the output file.\n",
    "\n",
    "**Outputs:**\n",
    "*   A new CSV file, which is a copy of your input CSV with an added 'sentiment' column. This file will be saved to your Google Drive in a directory named `Colab_Data` and will also be available for direct download.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Run the cells in this notebook sequentially from top to bottom.\n",
    "2.  When prompted, upload your CSV file.\n",
    "3.  Configure the parameters in the 'User Input Configuration' section.\n",
    "4.  Follow the prompts for Google Drive authentication if you haven't used Colab with your Drive recently."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "title": "Install Necessary Libraries"
   },
   "source": [
    "# This cell installs libraries required for the notebook.\n",
    "# It will only run once or if the libraries are not already installed in your Colab environment.\n",
    "print(\"Installing pandas and nltk...\")\n",
    "!pip install pandas nltk -q\n",
    "print(\"Installation complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "title": "Import Libraries"
   },
   "source": [
    "# This cell imports the libraries needed for the script.\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "import nltk\n",
    "import os # Will be used for checking Google Drive path\n",
    "\n",
    "# For sentiment analysis (VADER is a good starting point for a default lexicon)\n",
    "# Download VADER lexicon if not already downloaded\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    print("VADER lexicon found.")
except LookupError: # Catch LookupError specifically when resource is not found
    print("VADER lexicon not found. Downloading...")
    "    nltk.download('vader_lexicon', quiet=True)\n",
    print("VADER lexicon downloaded.")
except Exception as e: # Catch any other potential exceptions during find/download
    print(f"An error occurred while checking/downloading VADER lexicon: {e}")
    print("Attempting to download VADER lexicon anyway...")
    nltk.download('vader_lexicon', quiet=True) # Attempt download
    print("VADER lexicon download attempted.")

    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "print(\"Libraries imported.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "title": "Mount Google Drive & Prepare Output Directory"
   },
   "source": [
    "# This cell mounts your Google Drive to Colab, allowing the notebook to save files.\n",
    "# It also creates a directory named 'Colab_Data' in your Drive if it doesn't already exist.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "output_directory = '/content/drive/MyDrive/Colab_Data'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "    print(f\"Directory '{output_directory}' created in your Google Drive.\")\n",
    "else:\n",
    "    print(f\"Directory '{output_directory}' already exists in your Google Drive.\")\n",
    "\n",
    "# Test file to ensure Drive is writable (optional, can be removed)\n",
    "try:\n",
    "    with open(os.path.join(output_directory, 'drive_test.txt'), 'w') as f:\n",
    "        f.write('Google Drive connection successful.')\n",
    "    print(\"Successfully wrote a test file to Google Drive.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to Google Drive: {e}\")\n",
    "    print(\"Please ensure you have granted necessary permissions and have space in your Drive.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "title": "Upload Your CSV File"
   },
   "source": [
    "#@title Upload Your CSV File\n",
    "# Run this cell to upload your CSV file containing the lemmatized text.\n",
    "# The file should have one column with the text data you want to analyze.\n",
    "\n",
    "print(\"Please upload your CSV file.\")\n",
    "uploaded_file = files.upload()\n",
    "\n",
    "# Get the name of the uploaded file\n",
    "# Assuming only one file is uploaded\n",
    "if uploaded_file:\n",
    "    input_csv_name = next(iter(uploaded_file))\n",
    "    print(f\"Uploaded file '{input_csv_name}' successfully.\")\n",
    "    # Optional: Display first few lines to confirm it's a CSV\n",
    "    # try:\n",
    "    #   df_preview = pd.read_csv(input_csv_name)\n",
    "    #   print(\"Preview of your uploaded data:\")\n",
    "    #   print(df_preview.head())\n",
    "    # except Exception as e:\n",
    "    #   print(f\"Could not read the uploaded file as CSV: {e}. Please ensure it's a valid CSV.\")\n",
    "else:\n",
    "    input_csv_name = None\n",
    "    print(\"No file uploaded. Please run this cell again to upload your data.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "title": "User Input Configuration"
   },
   "source": [
    "#@title Configure Parameters\n",
    "# Please specify the details for your sentiment analysis.\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Input Data Configuration\n",
    "#@markdown Enter the name of the column in your CSV that contains the lemmatized text:\n",
    "text_column_name = \"lemmatized_text\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Sentiment Lexicon (Optional)\n",
    "#@markdown If you want to use a custom sentiment lexicon, provide the full path to the CSV file in your Google Drive.\n",
    "#@markdown The CSV should have two columns: 'word' and 'sentiment_score' (numeric, e.g., 1 for positive, -1 for negative).\n",
    "#@markdown Leave blank to use the default VADER sentiment lexicon.\n",
    "custom_lexicon_path = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Output File Configuration\n",
    "#@markdown Enter the desired name for your output CSV file (e.g., `sentiment_results.csv`):\n",
    "output_filename = \"sentiment_output.csv\" #@param {type:\"string\"}\n",
    "#@markdown ---\n",
    "\n",
    "print(\"Parameters configured:\")\n",
    "print(f\"  Text column name: '{text_column_name}'\")\n",
    "if custom_lexicon_path:\n",
    "    print(f\"  Custom lexicon path: '{custom_lexicon_path}'\")\n",
    "else:\n",
    "    print(\"  Using default VADER sentiment lexicon.\")\n",
    "print(f\"  Output filename: '{output_filename}'\")\n",
    "\n",
    "# Basic validation for output filename\n",
    "if not output_filename.endswith('.csv'):\n",
    "    output_filename += '.csv'\n",
    "    print(f\"  Adjusted output filename to: '{output_filename}' (ensured .csv extension)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "title": "Perform Sentiment Analysis"
   },
   "source": [
    "#@title Perform Sentiment Analysis\n",
    "# This cell processes your data and performs sentiment analysis.\n",
    "\n",
    "# Ensure a file was uploaded and parameters are set\n",
    "if input_csv_name is None:\n",
    "    print(\"Error: No CSV file was uploaded. Please go back to the 'Upload Your CSV File' cell and upload your data.\")\n",
    "elif not text_column_name:\n",
    "    print(\"Error: The 'text_column_name' is not specified. Please go to 'Configure Parameters' and set it.\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"Reading uploaded CSV file: {input_csv_name}...\")\n",
    "        df = pd.read_csv(input_csv_name)\n",
    "        print(\"CSV file loaded successfully.\")\n",
    "\n",
    "        if text_column_name not in df.columns:\n",
    "            print(f\"Error: Column '{text_column_name}' not found in the uploaded CSV.\")\n",
    "            print(f\"Available columns are: {df.columns.tolist()}\")\n",
    "        else:\n",
    "            print(f\"Using column '{text_column_name}' for sentiment analysis.\")\n",
    "\n",
    "            # Initialize sentiment analyzer\n",
    "            analyzer = SentimentIntensityAnalyzer() # Default VADER\n",
    "\n",
    "            # --- Lexicon Handling ---\n",
    "            if custom_lexicon_path:\n",
    "                print(f\"Attempting to load custom lexicon from: {custom_lexicon_path}...\")\n",
    "                try:\n",
    "                    # Ensure the path is accessible, typically it's a Drive path\n",
    "                    if not custom_lexicon_path.startswith('/content/drive/'):\n",
    "                         print(\"Warning: Custom lexicon path does not seem to be a Google Drive path. Ensure it's accessible.\")\n",
    "                    \n",
    "                    lexicon_df = pd.read_csv(custom_lexicon_path)\n",
    "                    if 'word' in lexicon_df.columns and 'sentiment_score' in lexicon_df.columns:\n",
    "                        custom_lexicon = dict(zip(lexicon_df['word'].astype(str), lexicon_df['sentiment_score'].astype(float)))\n",
    "                        # Update VADER's lexicon\n",
    "                        analyzer.lexicon.update(custom_lexicon)\n",
    "                        print(f\"Custom lexicon loaded and merged successfully. {len(custom_lexicon)} words added/updated.\")\n",
    "                    else:\n",
    "                        print(\"Error: Custom lexicon CSV must contain 'word' and 'sentiment_score' columns. Using default VADER.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading custom lexicon: {e}. Using default VADER.\")\n",
    "            else:\n",
    "                print(\"Using default VADER lexicon for sentiment analysis.\")\n",
    "\n",
    "            # --- Sentiment Analysis Function ---\n",
    "            def get_sentiment(text):\n",
    "                if pd.isna(text) or text.strip() == \"\":\n",
    "                    return \"neutral\" # Or handle as per preference (e.g., None, 'undefined')\n",
    "                \n",
    "                # VADER's compound score ranges from -1 (most extreme negative) to +1 (most extreme positive)\n",
    "                vs = analyzer.polarity_scores(str(text))\n",
    "                compound_score = vs['compound']\n",
    "                \n",
    "                if compound_score >= 0.05:\n",
    "                    return \"positive\"\n",
    "                elif compound_score <= -0.05:\n",
    "                    return \"negative\"\n",
    "                else:\n",
    "                    return \"neutral\"\n",
    "\n",
    "            print(\"Applying sentiment analysis...\")\n",
    "            df['sentiment'] = df[text_column_name].apply(get_sentiment)\n",
    "            print(\"Sentiment analysis complete.\")\n",
    "            print(\"Preview of data with sentiment scores:\")\n",
    "            print(df[[text_column_name, 'sentiment']].head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during sentiment analysis: {e}\")\n",
    "        df = None # Ensure df is None if there's an error"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "title": "Save and Download Results"
   },
   "source": [
    "#@title Save Results to Google Drive and Provide Download Link\n",
    "\n",
    "if 'df' in globals() and df is not None and 'sentiment' in df.columns:\n",
    "    try:\n",
    "        # Construct the full path for saving in Google Drive\n",
    "        output_drive_path = os.path.join(output_directory, output_filename)\n",
    "        \n",
    "        print(f\"Saving the results to: {output_drive_path} ...\")\n",
    "        df.to_csv(output_drive_path, index=False)\n",
    "        print(\"File saved successfully to your Google Drive.\")\n",
    "\n",
    "        print(f\"Providing download link for '{output_filename}' ...\")\n",
    "        files.download(output_drive_path) # Offer direct download as well\n",
    "        print(f\"If the download doesn't start automatically, please check your browser's download permissions for this site.\")\n",
    "        \n",
    "        print(\"\\n--- Results Summary ---\")\n",
    "        print(\"First 10 rows of the output data:\")\n",
    "        print(df.head(10))\n",
    "        print(\"\\nSentiment distribution (%):\")\n",
    "        print(df['sentiment'].value_counts(normalize=True) * 100)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving or downloading the file: {e}\")\n",
    "elif 'df' in globals() and df is not None and 'sentiment' not in df.columns:\n",
    "    print(\"Error: The 'sentiment' column was not successfully created. Cannot save results.\")\n",
    "    print(\"Please check the 'Perform Sentiment Analysis' cell for errors.\")\n",
    "else:\n",
    "    print(\"Error: No data to save. Please ensure the previous steps ran correctly and produced a DataFrame 'df'.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ✅ Analysis Complete!\n",
    "\n",
    "Thank you for using the Sentiment Analysis Tool!\n",
    "\n",
    "Your results have been:\n",
    "1.  Saved to your Google Drive in the `Colab_Data` folder (as `[Your Output File Name]`).\n",
    "2.  Offered as a direct download to your computer.\n",
    "\n",
    "**Troubleshooting & Tips:**\n",
    "*   **File Not Found Errors:** Ensure you've uploaded your CSV and that the Google Drive path for a custom lexicon (if used) is correct and accessible.\n",
    "*   **Incorrect Text Column:** Double-check the column name specified in the \"Configure Parameters\" section matches exactly with your CSV.\n",
    "*   **CSV Encoding:** This notebook assumes UTF-8 encoding for CSV files. If you encounter reading errors, your file might have a different encoding.\n",
    "*   **Permissions:** If Google Drive saving fails, ensure Colab has the necessary permissions to access your Drive. You might need to re-run the \"Mount Google Drive\" cell.\n",
    "*   **Large Files:** Processing very large files can take time and might hit Colab's resource limits. Consider processing data in chunks if needed.\n",
    "\n",
    "If you encounter other issues, reviewing the error messages in each cell can provide clues."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
